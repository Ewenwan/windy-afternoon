# 西瓜书概念
## 第12章 计算学习理论
- Page267: 计算学习理论（computational learning theory）

    计算学习理论研究的是关于通过“计算”来进行“学习”的理论，即关于机器学习的理论基础，其目的是分析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法设计。

- Page268: Jensen不等式

    $$f(\mathbb{E}(x)) \leqq \mathbb{E}(f(x))$$

    期望的函数小于函数的期望

- Page268: Hoeffding不等式

    若$$x_1,x_2,...,x_m$$为$$m$$个独立随机变量，且满足$$0\leqqx_i\leqq1$$，则对于任意$$\epsilon\geqq0$$有：
    $$P(\frac{1}{m}\sum_{i=1}^{m}x_i-\frac{1}{m}\sum_{i=1}^m\mathbb{E}(x_i)\geqq\epsilon)\leqqexp(-2m\epsilon^2)$$
    $$P(\mid\frac{1}{m}\sum_{i=1}^{m}x_i-\frac{1}{m}\sum_{i=1}^m\mathbb{E}(x_i)\mid\geqq\epsilon)\leqq2exp(-2m\epsilon^2)$$

- Page268: McDiarmid不等式

    若$$x_1,x_2,...,x_m$$为$$m$$个独立随机变量，且对任意$$1\leqqi\leqqm$$，函数$$f$$满足

    $$sup_{x_1,x_2,...,x_m, x_i^'}\midf(x_1,...,x_{i-1}, x_i^', x_{i+1}, ...,x_m)\mid\leqqc_i$$，
    则对任意$$\epsilon\geqq0$$，有
    $$P(f(x_1,...,x_m)-E(f(x_1,...,x_m))\geqq\epsilon)\leqqexp(\frac{-2\epsilon^2}{\sum_i c_i^2})$$
    $$P(\midf(x_1,...,x_m)-E(f(x_1,...,x_m))\mid\geqq\epsilon)\leqqexp(\frac{-2\epsilon^2}{\sum_i c_i^2})$$
- Page268: 概率近似正确
- Page268: 概念类(concept class)

    令c表示概念，这是从样本空间$$\mathcal{X}$$到标记空间$$\mathcal{Y}$$的映射，它决定示例x的真实标记y，若对任何样例(x,y)有c(x)=y成立，则称c为目标概念，所有我们希望学得的目标概念所构成的集合称为概念类，用符号$$\mathcal{C}$$表示。

- Page268: 假设空间（hypothesis space）

给定学习算法$$\mathfrak{L}$$，它所考虑的所有可能概念的集合称为“假设空间”，用符号$$\mathcal{H}$$表示。由于学习算法事先并不知道概念类的真实存在，因此假设空间和概念类往往不同。

- Page269: PAC辨识(PAC Identify)

    对于$$0<\epsilon, \delta<1$$，所有$$c\in\mathcal{C}$$和分布$$\mathcal{D}$$，若存在学习算法$$\mathfrak{L}$$，其输出假设$$h\in\mathcal{H}$$满足

    $$P(E(h)\leqq\epsilon)\geqq1-\delta$$

    则称学习算法$$\mathfrak{L}$$能从假设空间$$\mathcal{H}$$中PAC辨识概念类$$\mathcal{C}$$，这样的学习算法$$\mathcal{L}$$能从假设空间$$\mathcal{H}$$中PAC辨识概念类$$\mathcal{C}$$.

- Page269: PAC可学习(PAC Learnable)

    令$$m$$表示从分布$$\mathcal{D}$$中独立同分布采样得到的样例数目，$$0<\epsilon,\delta<1$$，对所有分布$$\mathcal{D}$$，若存在学习算法$$mathfrak{L}$$和多项式函数poly(.,.,.,.)，使得对于任何$$m\geqqpoly(1/\epsilon,1/\delta,size(x),size(c))$$, $$\mathfrak{L}$$能从假设空间$$\mathcal{H}$$中PAC辨识概念类$$\mathcal{C}$$，则称概念类$$\mathcal{C}$$对假设空间$$\mathcal{H}$$而言是PAC可学习的，也简称概念类$$\mathcal{C}$$是PAC可学习的。对于计算机算法来说，必须考虑时间复杂度，于是：

- Page270: PAC学习算法（PAC Learning Algorithm）

    若学习算法$$\mathfrak{L}$$使概念类$$\mathcal{C}$$为PAC可学习的，且$$\mathfrak{L}$$的运行时间也是多项式函数$$poly(1/\epsilon,1/\delta,size(x),size(c))$$，则称概念类$$\matchcal{C}$$是高效PAC可学习的，称$$\mathfrak{L}$$为概念类$$\mathcal{C}$$的PAC学习算法。

- Page269: 时间复杂度

    假定学习算法$$\mathfrak{L}$$处理每个样本的时间为常数，则$$\mathfrak{L}$$的时间复杂度等价于样本复杂度。

- Page270: 样本复杂度

    满足PAC学习算法$$\mathfrak{L}$$所需的$$m\geqq poly(1/\epsilon,1/\delta,size(x),size(c))$$中最小的m，称为学习算法$$\mathfrak{L}$$的样本复杂度。

- Page269: 不可分(272)
- Page269: 不一致
- Page269: 可分(270)

- Page270: 恰PAC可学习
- Page270: 有限假设空间
- Page273: VC维(274)
- Page273: 不可知PAC可学习
- Page273: 打散
- Page273: 对分
- Page273: 增长函数
- Page278: 经验风险最小化
- Page279: Rademacher复杂度
- Page284: 稳定性
- Page285: 均匀稳定性
